{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# 分隔符\n",
    "* 将大型数据资产划分为小部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "## 创建您的 .env 文件\n",
    "* 在 GitHub 仓库中，我们包含了一个名为 .env.example 的文件\n",
    "* 将该文件重命名为 .env 文件，在这里您将添加您的机密 API 密钥。请记得包括:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "我们将把我们的LangSmith项目称为**002-splitters**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e766aa-f3e2-491f-be99-d0c6b700d47a",
   "metadata": {},
   "source": [
    "## 跟踪操作\n",
    "从现在开始，我们可以从 LangSmith 跟踪此项目的操作 **和成本**：\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c811b84c-7054-49dd-b0ac-30f327f648a0",
   "metadata": {},
   "source": [
    "## 提醒：RAG 过程的步骤。\n",
    "* 当你加载一个文档时，你会得到字符串。有时这些字符串会太大，无法适应上下文窗口。在这种情况下，我们将使用 RAG 技术：\n",
    "    * **将文档分成小块**。\n",
    "    * 将文本块转换为数字块（嵌入）。\n",
    "    * 将嵌入加载到向量数据库（即向量存储）中。\n",
    "    * 加载问题并检索最相关的嵌入以进行回答。\n",
    "    * 将嵌入发送给 LLM 以正确格式化响应。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f6786d-16d2-4894-b8ef-95a7ebd19a94",
   "metadata": {},
   "source": [
    "## 分割器：将加载的文档分成小段文本\n",
    "* 也称为“文档转换器”。\n",
    "* 请参见文档页面 [这里](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/)。\n",
    "* 请参见内置分割器的列表 [这里](https://python.langchain.com/v0.1/docs/integrations/document_transformers/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de5c1e-1426-4cc8-8588-4ab7f1ffbcd0",
   "metadata": {},
   "source": [
    "#### 按字符简单分割：字符分割器\n",
    "* 这基于字符进行分割（默认使用\"\\n\\n\"），并通过字符数量测量块长度。\n",
    "* 在RAG（检索增强生成）应用的上下文中，特别是使用LangChain的工具，\"字符分割器\"是一种基于特定字符将文本划分为较小部分的方法。\n",
    "* 默认情况下，它使用双换行字符(\"\\n\\n\")来识别文本块的结束和开始。\n",
    "* 每个块根据其字符数量进行测量。\n",
    "* 这种简单的分割方法在RAG应用中非常有用，能够通过将大型文本块分解为可管理的较小部分来帮助管理和处理。这可以提高文本检索过程的效率和有效性，这在生成准确且具有上下文相关性的响应时至关重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db520c85-d916-4465-9a53-ee6a7c0b722d",
   "metadata": {},
   "source": [
    "这是一个简单的例子，用来说明“字符分割器”在使用默认分隔符（“\\n\\n”）的RAG应用中的工作方式。\n",
    "\n",
    "#### 原始文本：\n",
    "```\n",
    "你好，欢迎来到我们的商店！\n",
    "\n",
    "\\n\\n我们提供从电子产品到服装的各种商品。\n",
    "\n",
    "\\n\\n我们的营业时间是每天上午9点到晚上9点。\n",
    "\n",
    "\\n\\n如果您需要帮助找到任何东西，请随时询问。\n",
    "```\n",
    "\n",
    "#### 应用字符分割器后：\n",
    "1. **块 1：**\n",
    "   ```\n",
    "   你好，欢迎来到我们的商店！\n",
    "   ```\n",
    "\n",
    "2. **块 2：**\n",
    "   ```\n",
    "   我们提供从电子产品到服装的各种商品。\n",
    "   ```\n",
    "\n",
    "3. **块 3：**\n",
    "   ```\n",
    "   我们的营业时间是每天上午9点到晚上9点。\n",
    "   ```\n",
    "\n",
    "4. **块 4：**\n",
    "   ```\n",
    "   如果您需要帮助找到任何东西，请随时询问。\n",
    "   ```\n",
    "\n",
    "在这个例子中，文本根据段落之间的“\\n\\n”分割成四个块。每个块的大小适中，并清晰地与其他块分开，使RAG系统更容易处理和检索特定部分的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba8ec6a-9988-493f-9bc2-a1d72eb095b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./data/be-good.txt\")\n",
    "\n",
    "loaded_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9080df7c-9e81-4d2d-8713-9345e2ac8c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ecb63be-4c91-4bec-ba71-5d05dc962722",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063a35f4-da0c-4915-978d-be3d9f70befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a1f58df-c7b1-491c-93a1-c065591b28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.create_documents([loaded_data[0].page_content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c2bf32e-3cc8-4b59-bc8d-5617b37a62fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97c9e310-597b-46aa-accf-69eeda77f7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Be good')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "297dd163-7d2c-476b-b332-c2bf232461d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9b427-4002-4995-9db4-63d5afa9403c",
   "metadata": {},
   "source": [
    "#### Splitting with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "becc89c4-ec8c-468a-af28-711184d9c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas = [{\"chunk\": 0}, {\"chunk\": 1}]\n",
    "\n",
    "documents = text_splitter.create_documents(\n",
    "    [loaded_data[0].page_content, loaded_data[0].page_content], \n",
    "    metadatas=metadatas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a082af2-0913-4b8a-8e98-073e0bae2fbe",
   "metadata": {},
   "source": [
    "`CharacterTextSplitter` 是 LangChain 文本分割工具中的一个组件，帮助将文本分解为可管理的块，并可以选择为每个块附加元数据。以下是它的简单工作原理：\n",
    "\n",
    "1. **分割器的初始化**：分割器配置了几个参数：\n",
    "   - `separator`：这是文本分割的字符或字符串。在这个例子中，它被设置为 `\"\\n\\n\"`，意味着文本将在每次出现双换行符时分割。\n",
    "   - `chunk_size`：这决定了每个块的最大字符数。在这里，每个块最多可以长达 1000 个字符。\n",
    "   - `chunk_overlap`：这允许块之间重叠指定数量的字符，这里设置为 200。重叠有助于确保重要信息不会在块的末尾被尴尬地截断。\n",
    "   - `length_function`：这通常是一个测量文本长度的函数；`len` 只是简单地计算字符的数量。\n",
    "   - `is_separator_regex`：这指示分隔符是否是正则表达式。在这里，它是 `False`，意味着分隔符被视为字面字符串。\n",
    "\n",
    "2. **创建块**：`create_documents` 方法用于分割文本。它接收文本（或文本）和可选的元数据，并根据定义的参数分割文本。\n",
    "\n",
    "3. **附加元数据**：可选地，可以将元数据附加到每个块，以提供额外的上下文或标识符。例如，元数据可能会为每个块标记其序列号或根据内容进行分类。在这个例子中，像 `{\"chunk\": 0}` 的元数据可以表示这是第一个块。\n",
    "\n",
    "#### 示例代码说明：\n",
    "- **第一次使用分割器**：最初，分割器用于分割 `loaded_data[0].page_content` 的内容，没有元数据。这将仅根据提供的设置分割文本。\n",
    "- **第二次使用分割器**：然后相同的文本再次被分割，但这次提供了元数据 (`metadatas=[{\"chunk\": 0}, {\"chunk\": 1}]`)。第二次运行为每个块提供了额外的信息，以区分它们。\n",
    "\n",
    "#### 示例输出：\n",
    "- **块的数量**：这通常通过 `len(texts)` 打印，显示文本被分割成多少个块。\n",
    "- **第一个块**：通过打印 `texts[0]`，你将看到第一个块的内容。\n",
    "- **带元数据的第一个块**：在第二次分割操作后打印 `documents[0]` 将显示第一个文本块及其对应的元数据，说明元数据是如何与文本块关联的。\n",
    "\n",
    "这种方法在需要独立处理文本块但仍需某种形式的上下文或顺序链接的应用中特别有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f32ee1a-dcbc-4906-9e26-ff1c00f43e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'chunk': 0}, page_content='Be good')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a892bfb2-d1ab-4e9d-a4b2-25a4a6319577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Be good' metadata={'chunk': 0}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea671270",
   "metadata": {},
   "source": [
    "## 递归字符拆分器\n",
    "* 该文本拆分器是针对通用文本的推荐选择。\n",
    "* 它通过字符列表进行参数化。它尝试按顺序在这些字符上进行拆分，直到块足够小。默认列表是 [\"\\n\\n\", \"\\n\", \" \", \"\"]。\n",
    "* 这会尽可能保持所有段落（然后是句子，再然后是单词）在一起，因为这些通常被认为是语义上关系最强的文本片段。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c24c6b-f163-47da-9282-02d3f14b947f",
   "metadata": {},
   "source": [
    "#### 简单解释：\n",
    "\n",
    "* “递归字符分割器”是一种用于将文本分割成更小、更易于管理的块的方法，旨在保持文本的语义完整性。\n",
    "* 它通过尝试按照指定顺序使用字符列表来分割文本——首先是段落等较大单元，然后是句子，最后在必要时分割成单个单词。\n",
    "* 默认的分割序列为 [\"\\n\\n\", \"\\n\", \" \", \"\"]，这意味着它首先尝试在双换行符处分割文本以分隔段落，其次在单换行符处处理剩余的大块，接着根据空格孤立句子或短语，最后在需要更细分时使用空字符串。\n",
    "* 此方法特别有效，因为它努力保持文本块的意义和完整性，确保每个块都有连贯的信息。\n",
    "\n",
    "#### 使用示例：\n",
    "\n",
    "#### 原始文本：\n",
    "```\n",
    "你好，欢迎来到我们的商店！\n",
    "\n",
    "\\n\\n我们提供各种产品。我们的产品包括电子产品、服装和家用电器。\n",
    "\\n我们的员工在营业时间内为您提供帮助：每天上午9点到晚上9点。\n",
    "```\n",
    "\n",
    "#### 应用递归字符分割器：\n",
    "- 第一次尝试使用 `\"\\n\\n\"`：\n",
    "  1. **块 1:** `你好，欢迎来到我们的商店！`\n",
    "  2. **块 2:** `我们提供各种产品。我们的产品包括电子产品、服装和家用电器。\\n我们的员工在营业时间内为您提供帮助：每天上午9点到晚上9点。`\n",
    "\n",
    "- 第二次尝试使用 `\"\\n\"` 处理剩余的长块：\n",
    "  1. **新块 2:** `我们提供各种产品。我们的产品包括电子产品、服装和家用电器。`\n",
    "  2. **块 3:** `我们的员工在营业时间内为您提供帮助：每天上午9点到晚上9点。`\n",
    "\n",
    "- 由于所有块现在都已是可管理的大小，因此不需要进一步分割。\n",
    "\n",
    "在这个示例中，文本最初通过双换行符分成两个块。由于其中一个块仍然相当长，因此它随后使用单换行符进一步分割。每个块都保留了连贯的、完整的信息，反映出递归字符分割器在保持文本语义结构方面的有效使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c9adc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f4f0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=26,\n",
    "    chunk_overlap=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42d904ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyzabcdefg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7396e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"\n",
    "Data that Speak\n",
    "LLM Applications are revolutionizing industries such as \n",
    "banking, healthcare, insurance, education, legal, tourism, \n",
    "construction, logistics, marketing, sales, customer service, \n",
    "and even public administration.\n",
    "\n",
    "The aim of our programs is for students to learn how to \n",
    "create LLM Applications in the context of a business, \n",
    "which presents a set of challenges that are important \n",
    "to consider in advance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a2f91ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recursive_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a4b4a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data that Speak',\n",
       " 'LLM Applications are',\n",
       " 'are revolutionizing',\n",
       " 'industries such as',\n",
       " 'banking, healthcare,',\n",
       " 'insurance, education,',\n",
       " 'legal, tourism,',\n",
       " 'construction, logistics,',\n",
       " 'marketing, sales,',\n",
       " 'customer service,',\n",
       " 'and even public',\n",
       " 'administration.',\n",
       " 'The aim of our programs',\n",
       " 'is for students to learn',\n",
       " 'how to',\n",
       " 'create LLM Applications',\n",
       " 'in the context of a',\n",
       " 'a business,',\n",
       " 'which presents a set of',\n",
       " 'of challenges that are',\n",
       " 'are important',\n",
       " 'to consider in advance.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recursive_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7756d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6acfa6-5c64-417f-a2e1-c1f9939f1305",
   "metadata": {},
   "source": [
    "分隔符 `[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]` 指的是一系列字符和模式，用于将文本拆分成更小的部分，每个分隔符根据文本的结构执行特定功能：\n",
    "\n",
    "1. `\"\\n\\n\"` - 这个分隔符针对双换行符，通常用于表示文本中的独立段落或部分。在此处进行拆分旨在将不同主题或话题的内容块分开。\n",
    "\n",
    "2. `\"\\n\"` - 这个针对单换行符，通常表示段落中的新行或内容中的软换行，例如列表项或子段落之间。\n",
    "\n",
    "3. `\"(?<=\\. )\"` - 这是一个正则表达式，查找句号后跟一个空格，通常用于表示句子的结束。`(?<= )` 部分是正则表达式中的“向后查找”断言，这意味着它在拆分之前检查句号和空格的出现，但不将它们包括在拆分中，从而保持句子的完整性。\n",
    "\n",
    "4. `\" \"` - 这个针对单个空格字符，通常用于分隔单词。在空格上拆分可以将文本细分为单个单词或短语，特别是在需要更细粒度时非常有用。\n",
    "\n",
    "5. `\"\"` - 作为分隔符的空字符串在文本处理中用于将文本拆分成其各个字符，基本上将文本分解为最基本的元素。\n",
    "\n",
    "这些分隔符用于逐步将文本拆分成更小的块，从较大的结构性划分（如段落）开始，逐步移至单个字符的层次，具体取决于应用程序的需求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45e8a845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data that Speak\\nLLM Applications are revolutionizing industries such as \\nbanking, healthcare, insurance, education, legal, tourism,',\n",
       " 'construction, logistics, marketing, sales, customer service, \\nand even public administration.',\n",
       " 'The aim of our programs is for students to learn how to \\ncreate LLM Applications in the context of a business,',\n",
       " 'which presents a set of challenges that are important \\nto consider in advance.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_recursive_splitter.split_text(text2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
